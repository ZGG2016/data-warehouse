
[TOC]

## 1 日志数据生成与采集

修改 `application.yml` 中的 `mock.date` 修改生成数据的日期

启动kafka消费者

```sh
bin/kafka-console-consumer.sh --bootstrap-server bigdata102:9092 --topic topic_log
```

启动采集flume

```sh
bin/flume-ng agent -n a1 -c conf/ -f jobs/file_to_kafka.conf -Dflume.root.logger=info,console
```

开始生成数据

```sh
java -jar gmall2020-mock-log-2021-10-10.jar
```

成功的话，就能在kafka消费者端看到数据输出

## 2 业务数据生成与采集

创建数据库，并建表

```
create database gmall_flink;

use gmall_flink;

source /root/flink_realtime/dblog/gmall.sql
```

生成数据

```sh
java -jar gmall2020-mock-db-2021-11-14.jar 
```

注意：

```
#第一次执行必须设置为 1，后续不需要重置不用设置为 1
mock.clear=1
#第一次执行必须设置为 1，后续不需要重置不用设置为 1
mock.clear.user=1
```

采集数据通道：

先修改监控的数据库，并重启mysql服务（一定要重启）

```sh
root@bigdata102:/etc/mysql/mysql.conf.d# vi mysqld.cnf 
binlog-do-db=gmall_flink

root@bigdata102:/etc/mysql/mysql.conf.d# service mysql restart

#查看正在写入的binlog，要显示gmall_flink才配置正确
mysql> show master status;
```

启动maxwell

```sh
bin/maxwell --config config.properties --daemon
```

启动kafka消费者

```sh
bin/kafka-console-consumer.sh --bootstrap-server bigdata102:9092 --topic topic_db
```

生成数据

```sh
java -jar gmall2020-mock-db-2021-11-14.jar 
```


成功的话，就能在kafka消费者端看到数据输出

## 3 数仓dim

## 4 数仓dwd

## 5 数仓dws

## 6 数仓ads(可视化)